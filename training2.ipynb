{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir = data_path + \"processed_images\"\n",
    "table = pd.read_pickle(data_path + \"df.pkl\")\n",
    "tabular = table.iloc[0, 0:]\n",
    "y = tabular[\"price\"]\n",
    "image = Image.open(f\"{image_dir}/{tabular['zpid']}.png\")\n",
    "\n",
    "image = np.array(image)\n",
    "\n",
    "image = image[..., :3]\n",
    "image = transforms.functional.to_tensor(image)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \"\"\"Tabular and Image dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, pickle_file, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.pickle_file = pickle_file\n",
    "        self.tabular = pd.read_pickle(pickle_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tabular)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # Get a row from the table\n",
    "        tabular = self.tabular.iloc[idx, 0:]\n",
    "\n",
    "        # Get the target feature\n",
    "        y = tabular[\"price\"]\n",
    "\n",
    "        # Open the image\n",
    "        image = Image.open(f\"{self.image_dir}/{tabular['zpid']}.png\")\n",
    "        image = np.array(image)\n",
    "\n",
    "        # Remove the 4th dimension from the image (RGBA)\n",
    "        image = image[..., :3]\n",
    "\n",
    "        image = transforms.functional.to_tensor(image)\n",
    "\n",
    "        tabular = tabular[[\"latitude\", \"longitude\", \"beds\", \"baths\", \"area\"]]\n",
    "        tabular = tabular.tolist()\n",
    "        tabular = torch.FloatTensor(tabular)\n",
    "\n",
    "        return image, tabular, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_size, output_size):\n",
    "    block = nn.Sequential(\n",
    "        nn.Conv2d(input_size, output_size, (3, 3)), \n",
    "        nn.ReLU(), \n",
    "        nn.BatchNorm2d(output_size), \n",
    "        nn.MaxPool2d((2, 2)),\n",
    "    )\n",
    "\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, lr: float = 1e-3, num_workers: int = 4, batch_size: int = 32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.conv1 = conv_block(3, 16)\n",
    "        self.conv2 = conv_block(16, 32)\n",
    "        self.conv3 = conv_block(32, 64)\n",
    "\n",
    "        self.ln1 = nn.Linear(64 * 26 * 26, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batchnorm = nn.BatchNorm1d(16)\n",
    "        self.dropout = nn.Dropout2d(0.5)\n",
    "        self.ln2 = nn.Linear(16, 5)\n",
    "\n",
    "        self.ln4 = nn.Linear(5, 10)\n",
    "        self.ln5 = nn.Linear(10, 10)\n",
    "        self.ln6 = nn.Linear(10, 5)\n",
    "        self.ln7 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, img, tab):\n",
    "        img = self.conv1(img)\n",
    "        img = self.conv2(img)\n",
    "        img = self.conv3(img)\n",
    "        img = img.reshape(img.shape[0], -1)\n",
    "        img = self.ln1(img)\n",
    "        img = self.relu(img)\n",
    "        img = self.batchnorm(img)\n",
    "        img = self.dropout(img)\n",
    "        img = self.ln2(img)\n",
    "        img = self.relu(img)\n",
    "\n",
    "        tab = self.ln4(tab)\n",
    "        tab = self.relu(tab)\n",
    "        tab = self.ln5(tab)\n",
    "        tab = self.relu(tab)\n",
    "        tab = self.ln6(tab)\n",
    "        tab = self.relu(tab)\n",
    "\n",
    "        x = torch.cat((img, tab), dim=1)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return self.ln7(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
